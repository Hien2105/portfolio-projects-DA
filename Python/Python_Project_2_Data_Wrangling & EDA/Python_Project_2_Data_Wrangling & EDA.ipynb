{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "payment_report = pd.read_csv('C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Python\\\\Project_2\\\\payment_report.csv')\n",
    "product = pd.read_csv('C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Python\\\\Project_2\\\\product.csv')\n",
    "transactions = pd.read_csv('C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Python\\\\Project_2\\\\transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part I: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate count: 0\n",
      "Null count:\n",
      "report_month     0\n",
      "payment_group    0\n",
      "product_id       0\n",
      "source_id        0\n",
      "volume           0\n",
      "category         0\n",
      "team_own         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 897 entries, 0 to 896\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   report_month   897 non-null    datetime64[ns]\n",
      " 1   payment_group  897 non-null    string        \n",
      " 2   product_id     897 non-null    int64         \n",
      " 3   source_id      897 non-null    int64         \n",
      " 4   volume         897 non-null    int64         \n",
      " 5   category       897 non-null    string        \n",
      " 6   team_own       897 non-null    string        \n",
      "dtypes: datetime64[ns](1), int64(3), string(3)\n",
      "memory usage: 49.2 KB\n",
      "None\n",
      "                     report_month    product_id  source_id        volume\n",
      "count                         897    897.000000      897.0  8.970000e+02\n",
      "mean   2023-02-19 07:45:33.110368   1139.573021       45.0  1.338153e+08\n",
      "min           2023-01-01 00:00:00     12.000000       45.0  1.000000e+04\n",
      "25%           2023-02-01 00:00:00    634.000000       45.0  1.258000e+06\n",
      "50%           2023-03-01 00:00:00   1023.000000       45.0  7.469786e+06\n",
      "75%           2023-04-01 00:00:00   1578.000000       45.0  4.770741e+07\n",
      "max           2023-04-01 00:00:00  15067.000000       45.0  4.926051e+09\n",
      "std                           NaN   1161.547355        0.0  4.614672e+08\n"
     ]
    }
   ],
   "source": [
    "# Df payment_enriched (Merge payment_report.csv with product.csv)\n",
    "payment_enriched = payment_report.merge(product, on='product_id')\n",
    "#change column type \n",
    "payment_enriched['report_month'] = pd.to_datetime(payment_enriched['report_month'])\n",
    "payment_enriched['payment_group'] = payment_enriched['payment_group'].astype('string')\n",
    "payment_enriched['category'] = payment_enriched['category'].astype('string')\n",
    "payment_enriched['team_own'] = payment_enriched['team_own'].astype('string')\n",
    "#check dup\n",
    "print(\"duplicate count: \" + str(payment_enriched.duplicated().sum()))\n",
    "#check null\n",
    "print(\"Null count:\")\n",
    "print(payment_enriched.isnull().sum())\n",
    "print(payment_enriched.info())\n",
    "print(payment_enriched.describe())\n",
    "\n",
    "\n",
    "# EDA summary\n",
    "#1 Change report_month, payment_group, category, team_own type to match the column values\n",
    "#2 Check duplicate\n",
    "#3 Check Null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate count: 28\n",
      "duplicate count after remove: 0\n",
      "Null count:\n",
      "transaction_id          0\n",
      "merchant_id             0\n",
      "volume                  0\n",
      "transType               0\n",
      "transStatus             0\n",
      "sender_id               0\n",
      "receiver_id             0\n",
      "extra_info        1317907\n",
      "timeStamp               0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324002 entries, 0 to 1324001\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   transaction_id  1324002 non-null  int64 \n",
      " 1   merchant_id     1324002 non-null  int64 \n",
      " 2   volume          1324002 non-null  int64 \n",
      " 3   transType       1324002 non-null  int64 \n",
      " 4   transStatus     1324002 non-null  int64 \n",
      " 5   sender_id       1324002 non-null  int64 \n",
      " 6   receiver_id     1324002 non-null  int64 \n",
      " 7   extra_info      6095 non-null     object\n",
      " 8   timeStamp       1324002 non-null  int64 \n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 90.9+ MB\n",
      "None\n",
      "       transaction_id   merchant_id        volume     transType   transStatus  \\\n",
      "count    1.324002e+06  1.324002e+06  1.324002e+06  1.324002e+06  1.324002e+06   \n",
      "mean     3.002233e+09  2.460318e+03  2.388059e+05  6.979222e+00  1.393262e+01   \n",
      "std      1.042606e+07  3.304277e+03  9.681009e+05  7.459714e+00  5.533720e+01   \n",
      "min      3.000000e+09  5.000000e+00  1.000000e+00  2.000000e+00  1.000000e+00   \n",
      "25%      3.001121e+09  3.050000e+02  1.000000e+04  2.000000e+00  1.000000e+00   \n",
      "50%      3.002200e+09  2.250000e+03  3.000000e+04  2.000000e+00  1.000000e+00   \n",
      "75%      3.003255e+09  2.270000e+03  1.000000e+05  8.000000e+00  1.000000e+00   \n",
      "max      6.000066e+09  1.625250e+05  7.869148e+07  3.000000e+01  1.333000e+03   \n",
      "\n",
      "          sender_id   receiver_id     timeStamp  \n",
      "count  1.324002e+06  1.324002e+06  1.324002e+06  \n",
      "mean   9.956267e+07  1.825384e+08  1.683130e+12  \n",
      "std    6.120830e+08  8.717789e+08  1.707815e+08  \n",
      "min    0.000000e+00  0.000000e+00  1.682874e+12  \n",
      "25%    1.004013e+07  4.060000e+04  1.682994e+12  \n",
      "50%    1.057186e+07  3.529736e+06  1.683097e+12  \n",
      "75%    2.100163e+07  2.451345e+07  1.683269e+12  \n",
      "max    6.993439e+09  2.100000e+10  1.683479e+12  \n"
     ]
    }
   ],
   "source": [
    "#Df transactions\n",
    "#change column type and abs id column to prevent - value \n",
    "transactions['sender_id'] = transactions['sender_id'].fillna(0).astype(int)\n",
    "transactions['receiver_id'] = transactions['receiver_id'].fillna(0).astype(int)\n",
    "transactions['receiver_id'] = transactions['receiver_id'].abs()\n",
    "transactions['transStatus'] = transactions['transStatus'].abs()\n",
    "#check dup and remove dup\n",
    "print(\"duplicate count: \" + str(transactions.duplicated().sum()))\n",
    "transaction_remove_dup = transactions.drop_duplicates(subset = ['transaction_id'])\n",
    "print(\"duplicate count after remove: \" + str(transaction_remove_dup.duplicated().sum()))\n",
    "#check null\n",
    "print(\"Null count:\")\n",
    "print(transactions.isnull().sum())\n",
    "print(transactions.info())\n",
    "print(transactions.describe())\n",
    "\n",
    "# EDA summary\n",
    "#1 Change sender_id, receiver_id type to match the column values \n",
    "#1.1 fill Na value of sender_id, receiver_id\n",
    "#1.2 abs value to prevent - value\n",
    "#2 Check duplicate => remove dup\n",
    "#3 Check Null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part II: Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 volume\n",
      "product_id             \n",
      "1976        61797583647\n",
      "429         14667676567\n",
      "372         13713658515\n"
     ]
    }
   ],
   "source": [
    "#1. Top 3 product_ids with the highest volume.\n",
    "top_3_product_id = pd.DataFrame(payment_report.groupby('product_id')['volume'].sum().sort_values(ascending=False).head(3))\n",
    "print(top_3_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            team_own\n",
      "product_id          \n",
      "9                  1\n",
      "10                 1\n",
      "11                 1\n",
      "12                 1\n",
      "14                 1\n",
      "...              ...\n",
      "2408               1\n",
      "2419               1\n",
      "2587               1\n",
      "10039              1\n",
      "15067              1\n",
      "\n",
      "[492 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. Given that 1 product_id is only owed by 1 team, are there any abnormal products against this rule?\n",
    "check = pd.DataFrame(product.groupby('product_id')['team_own'].count().sort_index())\n",
    "print(check)\n",
    "\n",
    "#There is no abnormal products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volume\n",
      "team_own          \n",
      "APS       51141753\n",
      "            volume\n",
      "category          \n",
      "PXXXXXE   25232438\n"
     ]
    }
   ],
   "source": [
    "#3 Find the team has had the lowest performance (lowest volume) since Q2.2023. Find the category that contributes the least to that team.\n",
    "payment_report_team = payment_report.merge(product, on='product_id')\n",
    "#filter time\n",
    "payment_report_team['report_month'] = pd.to_datetime(payment_report_team['report_month'])\n",
    "Q2_payment = payment_report_team[payment_report_team['report_month'] >= '04-2023']\n",
    "#lowest performance team\n",
    "lowest_performance = pd.DataFrame(Q2_payment.groupby(['team_own'])['volume'].sum().sort_values().head(1))\n",
    "lowest_performance_filtered = Q2_payment[Q2_payment['team_own'] == 'APS']\n",
    "#category that contributes the least to that team\n",
    "lowest_category = pd.DataFrame(lowest_performance_filtered.groupby(['category'])['volume'].sum().sort_values().head(1))\n",
    "print(lowest_performance)\n",
    "print(lowest_category)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                volume\n",
      "source_id             \n",
      "38         36527454759\n"
     ]
    }
   ],
   "source": [
    "#4 Find the contribution of source_ids of refund transactions (payment_group = ‘refund’), what is the source_id with the highest contribution?\n",
    "payment_report_refund = payment_report[payment_report['payment_group'] == 'refund']\n",
    "payment_report_refund = pd.DataFrame(payment_report_refund.groupby('source_id')['volume'].sum().sort_values(ascending=False).head(1))\n",
    "print(payment_report_refund)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         transaction_id  transType  merchant_id            transaction_type\n",
      "0            3002692434         24            5         Invalid Transaction\n",
      "1            3002692437          2          305         Payment Transaction\n",
      "2            3001960110         22         7255         Invalid Transaction\n",
      "3            3002680710          2         2270    Top Up Money Transaction\n",
      "4            3002680713          2         2275         Payment Transaction\n",
      "...                 ...        ...          ...                         ...\n",
      "1323997      3003723030          2          305         Payment Transaction\n",
      "1323998      3003723033          2         2270    Top Up Money Transaction\n",
      "1323999      3003723036          2         2270    Top Up Money Transaction\n",
      "1324000      3003723039         22            5         Invalid Transaction\n",
      "1324001      3003602967          8         2250  Transfer Money Transaction\n",
      "\n",
      "[1323974 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_8224\\2661981769.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_remove_dup.loc[:, 'transaction_type'] = 'Invalid Transaction'\n"
     ]
    }
   ],
   "source": [
    "#5 Define type of transactions (‘transaction_type’) for each row\n",
    "transaction_remove_dup.loc[:, 'transaction_type'] = 'Invalid Transaction'\n",
    "transaction_remove_dup.loc[transaction_remove_dup['transType'] == 2, 'transaction_type'] = 'Payment Transaction'\n",
    "transaction_remove_dup.loc[(transaction_remove_dup['transType'] == 2) & (transaction_remove_dup['merchant_id'] == 1205), 'transaction_type'] = 'Bank Transfer Transaction'\n",
    "transaction_remove_dup.loc[(transaction_remove_dup['transType'] == 2) & (transaction_remove_dup['merchant_id'] == 2260), 'transaction_type'] = 'Withdraw Money Transaction'\n",
    "transaction_remove_dup.loc[(transaction_remove_dup['transType'] == 2) & (transaction_remove_dup['merchant_id'] == 2270), 'transaction_type'] = 'Top Up Money Transaction'\n",
    "transaction_remove_dup.loc[transaction_remove_dup['transType'] == 8, 'transaction_type'] = 'Split Bill Transaction'\n",
    "transaction_remove_dup.loc[(transaction_remove_dup['transType'] == 8) & (transaction_remove_dup['merchant_id'] == 2250), 'transaction_type'] = 'Transfer Money Transaction'\n",
    "print(transaction_remove_dup[['transaction_id','transType','merchant_id', 'transaction_type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            transaction_id        volume  sender_id  \\\n",
      "transaction_type                                                      \n",
      "Bank Transfer Transaction            37879   50605806190      23156   \n",
      "Payment Transaction                 398665   71850608441     139583   \n",
      "Split Bill Transaction                1376       4901464       1323   \n",
      "Top Up Money Transaction            290498  108605618829     110409   \n",
      "Transfer Money Transaction          341173   37032880492      39021   \n",
      "Withdraw Money Transaction           33725   23418181420      24814   \n",
      "\n",
      "                            receiver_id  \n",
      "transaction_type                         \n",
      "Bank Transfer Transaction          9272  \n",
      "Payment Transaction              113297  \n",
      "Split Bill Transaction              572  \n",
      "Top Up Money Transaction         110409  \n",
      "Transfer Money Transaction        34585  \n",
      "Withdraw Money Transaction        24814  \n"
     ]
    }
   ],
   "source": [
    "#6 Of each transaction type (excluding invalid transactions): find the number of transactions, volume, senders and receivers.\n",
    "transaction_remove_dup_filtered = transaction_remove_dup[transaction_remove_dup['transaction_type'] != 'Invalid Transaction']\n",
    "transaction_remove_dup_filtered = transaction_remove_dup_filtered.groupby('transaction_type')[['transaction_id', 'volume', 'sender_id', 'receiver_id']].agg({'transaction_id':'count','volume':'sum','sender_id':'nunique','receiver_id':'nunique'})\n",
    "print(transaction_remove_dup_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
